{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9f405f",
   "metadata": {},
   "source": [
    "# Add Classification Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b1c9d",
   "metadata": {},
   "source": [
    "In this recipe, we will be covering how you can add classification model predictions to your dataset. First we will go through how to add predictions using the [FiftyOne Model Zoo](https://docs.voxel51.com/user_guide/model_zoo/index.html) and `apply_model`. In the second part, we will demonstrate how to add your classification predictions from your own custom model. Feel free to skip ahead if you are interested in only custom models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ed1ce",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61f3fc",
   "metadata": {},
   "source": [
    "If you haven't already, install FiftyOne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8091d56",
   "metadata": {},
   "source": [
    "Let's kick things off by loading in the zoo dataset [imagenet-sample](https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#dataset-zoo-imagenet-sample). The dataset contains 1,000 images, one randomly chosen from each class of the validation split of the ImageNet 2012 dataset. We will use it our example dataset for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9468c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\"imagenet-sample\")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbeaeca",
   "metadata": {},
   "source": [
    "## Adding Predictions With Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea156a59",
   "metadata": {},
   "source": [
    "With FiftyOne, you have tons of pretrained models at your disposal to use via the [FiftyOne Model Zoo](https://docs.voxel51.com/user_guide/model_zoo/index.html) or using one of our [integrations](https://docs.voxel51.com/integrations/index.html) such as [HuggingFace](https://docs.voxel51.com/integrations/huggingface.html)! To get started using them, first load the model in and pass it into the `apply_model` function. We will use [mobilenet-v2](https://docs.voxel51.com/user_guide/model_zoo/models.html#mobilenet-v2-imagenet-torch) from the model zoo first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "dataset.apply_model(model, label_field=\"zoo_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb5c97",
   "metadata": {},
   "source": [
    "Next, lets try a transformer for image classification from HuggingFace. Check out [here](https://docs.voxel51.com/integrations/huggingface.html#image-classification) for more options for HuggingFace transformers for image classification! Afterwards, we can visualize our results and see our predictions in the app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea260918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BeitForImageClassification\n",
    "\n",
    "model = BeitForImageClassification.from_pretrained(\n",
    "    \"microsoft/beit-base-patch16-224\"\n",
    ")\n",
    "dataset.apply_model(model, label_field=\"hf_predictions\")\n",
    "\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6034a6a",
   "metadata": {},
   "source": [
    "![Add_predictions](../assets/add_predictions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c39806",
   "metadata": {},
   "source": [
    "## Adding Predictions from a Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5c80b",
   "metadata": {},
   "source": [
    "Often you may bring your own model to add classification predictions! Let's walkthrough how using `torchvision` resnet50 we can add classification labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa2d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you dont have torchvision installed\n",
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7099e8",
   "metadata": {},
   "source": [
    "We start by initializing our model from torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Step 1: Initialize model with the best available weights\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa08c4",
   "metadata": {},
   "source": [
    "Before we jump into adding predictions to the _whole_ dataset, we will start with a single sample first. The pattern for adding custom labels looks like this:\n",
    "\n",
    "1. Load the sample image\n",
    "2. Perform any necessary preprocessing\n",
    "3. Inference on the image\n",
    "4. Grab the prediction and confidence of the model_output\n",
    "5. Add the values as a label to your sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae7c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tench: 54.5%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the image from the sample.filepath\n",
    "sample = dataset.first()\n",
    "img = read_image(sample.filepath)\n",
    "\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "# Step 4: Use the model and print the predicted category\n",
    "prediction = model(batch).squeeze(0).softmax(0)\n",
    "class_id = prediction.argmax().item()\n",
    "score = prediction[class_id].item()\n",
    "category_name = weights.meta[\"categories\"][class_id]\n",
    "print(f\"{category_name}: {100 * score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dad1b0",
   "metadata": {},
   "source": [
    "We can add a new field easily by just using `sample[\"new_field\"] = value`. We can add a [classification](https://docs.voxel51.com/user_guide/using_datasets.html#classification) label like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871b5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Classification: {\n",
      "    'id': '6642742f831fa59b38e3d03c',\n",
      "    'tags': [],\n",
      "    'label': 'tench',\n",
      "    'confidence': 0.5446103811264038,\n",
      "    'logits': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Add the label and confidence score to the sample\n",
    "sample[\"custom_predictions\"] = fo.Classification(label=category_name, confidence=score)\n",
    "sample.save() # Always remember to save after!\n",
    "\n",
    "print(sample.custom_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28b4f2",
   "metadata": {},
   "source": [
    "Now that we know how to do a single sample, we can create a function that takes in our model and our dataset to add predictions to all samples! We copy the same pattern but iterate through our dataset this time to grab each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb8422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(dataset, model):\n",
    "    \n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    preprocess = weights.transforms()\n",
    "    \n",
    "    for sample in dataset:\n",
    "        \n",
    "        img = read_image(sample.filepath)\n",
    "\n",
    "        batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "        prediction = model(batch).squeeze(0).softmax(0)\n",
    "        class_id = prediction.argmax().item()\n",
    "        score = prediction[class_id].item()\n",
    "        category_name = weights.meta[\"categories\"][class_id]\n",
    "\n",
    "        sample[\"custom_predictions\"] = fo.Classification(label=category_name, confidence=score)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386acc30",
   "metadata": {},
   "source": [
    "Now we can call our new function and visualize our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee240f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=0ed85f07-e9fa-4485-82fd-cc6b67ce9cce\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7e987ca9b7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_predictions(dataset,model)\n",
    "session.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
