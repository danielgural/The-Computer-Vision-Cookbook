{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8d1c35",
   "metadata": {},
   "source": [
    "# Find Classification Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817ce6c",
   "metadata": {},
   "source": [
    "Annotations mistakes create an artificial ceiling on the performance of your models. However, finding these mistakes by hand is almost as time consuming as the original annotation work! Luckily, FiftyOne comes to the rescue!\n",
    "\n",
    "In this tutorial, we explore how FiftyOne can be used to help you find mistakes in your classification annotations.\n",
    "\n",
    "We’ll cover the following concepts:\n",
    "\n",
    "- Loading a zoo dataset with FiftyOne\n",
    "\n",
    "- Adding model predictions to your dataset\n",
    "\n",
    "- Computing insights into your dataset relating to possible label mistakes\n",
    "\n",
    "- Visualizing mistakes in the FiftyOne App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c4637",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edbc1c",
   "metadata": {},
   "source": [
    "If you haven't already, install FiftyOne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9124095",
   "metadata": {},
   "source": [
    "Let's kick things off by loading in the zoo dataset [imagenet-sample](https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#dataset-zoo-imagenet-sample). The dataset contains 1,000 images, one randomly chosen from each class of the validation split of the ImageNet 2012 dataset. We will use it our example dataset for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\"imagenet-sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8141f9f",
   "metadata": {},
   "source": [
    "For this walkthrough, we will artificially perturb an existing dataset with mistakes on the labels. Of course, in your normal workflow, you would not add labeling mistakes; this is only for the sake of the walkthrough.\n",
    "\n",
    "In order to accomplish this, we randomly break 10% (100 sample) of all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fae07a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get the ImageNet classes list\n",
    "classes = dataset.default_classes\n",
    "\n",
    "\n",
    "# Artificially corrupt 10% of the labels\n",
    "num_mistakes = int(0.1 * len(dataset))\n",
    "samples_to_corrupt = dataset.take(num_mistakes)\n",
    "\n",
    "for sample in samples_to_corrupt:\n",
    "    \n",
    "    mistake_class = random.randint(0, 999)\n",
    "    \n",
    "    # Make sure it gets corrupted\n",
    "    while classes[mistake_class] == sample.ground_truth.label:\n",
    "        mistake_class = random.randint(0, 999)\n",
    "\n",
    "    # Tag and corrupt the sample\n",
    "    sample.tags.append(\"mistake\")\n",
    "    sample.ground_truth.label = classes[mistake_class]\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95babae9",
   "metadata": {},
   "source": [
    "Let’s print some information about the dataset to verify the operation that we performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a99c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ground truth labels are now mistakes\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples with the `mistake` tag\n",
    "num_mistakes = len(dataset.match_tags(\"mistake\"))\n",
    "print(\"%d ground truth labels are now mistakes\" % num_mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83d759",
   "metadata": {},
   "source": [
    "## Add predictions to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0df9ce",
   "metadata": {},
   "source": [
    "Next, we need to add some predictions to our dataset. We will use [mobilenet-v2](https://docs.voxel51.com/user_guide/model_zoo/models.html#mobilenet-v2-imagenet-torch) from the model zoo! We can add predictions easily with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64060d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1000/1000 [9.5s elapsed, 0s remaining, 92.8 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "\n",
    "dataset.apply_model(model, label_field=\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d927e1d",
   "metadata": {},
   "source": [
    "We can print our dataset to verify that the predictions have been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728ff70",
   "metadata": {},
   "source": [
    "Let's check out our new predictions in the app as well! See if you can spot any mistakes already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541c08f",
   "metadata": {},
   "source": [
    "![imagenet-sample](../assets/imagenet-sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356e9d5",
   "metadata": {},
   "source": [
    "## Find the mistakes with FiftyOne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3066d71",
   "metadata": {},
   "source": [
    "Now we can run a method from FiftyOne that estimates the mistakenness of the ground samples for which we generated predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "# Compute mistakenness\n",
    "fob.compute_mistakenness(dataset, \"predictions\", label_field=\"ground_truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad44551",
   "metadata": {},
   "source": [
    "The above method added mistakenness field to all samples for which we added predictions. We can easily sort by likelihood of mistakenness from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f4fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     imagenet-sample\n",
      "Media type:  image\n",
      "Num samples: 1000\n",
      "Sample fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    predictions:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    mistakenness: fiftyone.core.fields.FloatField\n",
      "View stages:\n",
      "    1. SortBy(field_or_expr='mistakenness', reverse=True, create_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Sort by likelihood of mistake (most likely first)\n",
    "mistake_view = (dataset\n",
    "    .sort_by(\"mistakenness\", reverse=True)\n",
    ")\n",
    "\n",
    "# Print some information about the view\n",
    "print(mistake_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = mistake_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac8021",
   "metadata": {},
   "source": [
    "![class-mistakes](../assets/class-mistakes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1602c",
   "metadata": {},
   "source": [
    "In a real world scenario, we would then take the ground truth classifications that are likely mistakes and send them off to our annotation provider of choice as annotations to be reviewed. In FiftyOne, we can tag our samples and export them for annotation job with one of labeling integrations: [CVAT](https://docs.voxel51.com/integrations/cvat.html), [Label Studio](https://docs.voxel51.com/integrations/labelstudio.html), [V7](https://docs.voxel51.com/integrations/v7.html), or [LabelBox](https://docs.voxel51.com/integrations/labelbox.html)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
