{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0d965d",
   "metadata": {},
   "source": [
    "# Fine Tune Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f032501",
   "metadata": {},
   "source": [
    "In this model, we will show a very quick walkthrough on how to fine tune YOLOv8 using FiftyOne. We will go through how to load a dataset from HuggingFace, export the data to YOLO format, and then use Ultralytics to fine tune. At the end, we can easily apply our model to our entire dataset to view the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5128dc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467eb8ba",
   "metadata": {},
   "source": [
    "If you haven't yet, install FiftyOne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff6a11",
   "metadata": {},
   "source": [
    "We will also need some other libraries in order to train our YOLOv8 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d79649",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a7dfd",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152f122",
   "metadata": {},
   "source": [
    "For our example workflow, I will be using the [VisDrone dataset](https://github.com/VisDrone/VisDrone-Dataset?tab=readme-ov-file), a state of the art drone imagery dataset from Lab of Machine Learning and Data Mining, Tianjin University, China. It features a wide range of locations, time of day, objects, and angles. We can download it directly from [HuggingFace](https://huggingface.co/datasets/Voxel51/VisDrone2019-DET) using the FiftyOne HuggingFace Hub integration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c79ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "# Load the dataset\n",
    "dataset = fouh.load_from_hub(\"Voxel51/VisDrone2019-DET\",overwrite=True)\n",
    "\n",
    "# Launch the App\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b81c47",
   "metadata": {},
   "source": [
    "![Visdrone](../assets/visdrone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb100d",
   "metadata": {},
   "source": [
    "We need to export the dataset in YOLO format in order to train YOLOv8. We do so by randomly splitting and using the export method provided by the `dataset` class. This will allow ultralytics to automatically ingest our dataset without having to worry about converting any bounding boxes or labels manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 2804/2804 [21.3s elapsed, 0s remaining, 180.4 samples/s]      \n",
      "Directory 'VisDrone_YOLO/' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 8578/8578 [1.1m elapsed, 0s remaining, 153.2 samples/s]      \n",
      "Directory 'VisDrone_YOLO/' already exists; export will be merged with existing files\n",
      "   6% |/--------------|  101/1610 [1.2s elapsed, 18.3s remaining, 82.6 samples/s]     "
     ]
    }
   ],
   "source": [
    "import fiftyone.utils.random as four\n",
    "\n",
    "classes = dataset.distinct(\"ground_truth.detections.label\")\n",
    "\n",
    "four.random_split(dataset, {\"val\": 0.15, \"train\": 0.85})\n",
    "\n",
    "\n",
    "for split in [\"val\",\"train\",\"test\"]:\n",
    "    view =  dataset.match_tags(split)\n",
    "    view.export(\n",
    "        export_dir=\"VisDrone_YOLO/\",\n",
    "        split=split,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        classes=classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca6040",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49554ea",
   "metadata": {},
   "source": [
    "We begin training using the Ultralytics library and passing in our exported `dataset.yaml`. I encourage you to try different hyperparameter setups and training configs based on your data. Check out all of your options [here](https://docs.ultralytics.com/modes/train/) at the Ultralytics Docs page! Once you have trained your model, you can pass it directly into `apply_model` to add the predicitions to your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc88e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Build a YOLOv9c model from pretrained weight\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "# Train the model on the  dataset for 1 epochs, set project name for experiment_name, name for the run name\n",
    "model.train(\n",
    "    data='VisDrone_YOLO/dataset.yaml',\n",
    "    imgsz=640, \n",
    "    batch=1,\n",
    ")\n",
    "\n",
    "# Add predictions to our dataset\n",
    "dataset.apply_model(model, label_field=\"YOLOv8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b911e69",
   "metadata": {},
   "source": [
    "![post-training](../assets/high_cf_fp.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3b00",
   "metadata": {},
   "source": [
    "Great ML engineers don't stop here however! Check out other recipes on how to find annotation mistakes, evaluate your model, compare multiple models or more to make your model even better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f494e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
