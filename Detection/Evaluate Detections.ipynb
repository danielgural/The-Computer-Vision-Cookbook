{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae5766",
   "metadata": {},
   "source": [
    "# Evaluate Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc17f2a",
   "metadata": {},
   "source": [
    "This recipe demonstrates how to use FiftyOne to perform hands-on evaluation of your detection model.\n",
    "\n",
    "It covers the following concepts:\n",
    "\n",
    "- Loading a dataset with ground truth labels [into FiftyOne](https://docs.voxel51.com/user_guide/dataset_creation/index.html)\n",
    "- [Adding model predictions](https://docs.voxel51.com/recipes/adding_detections.html) to your dataset\n",
    "- [Evaluating your model](https://docs.voxel51.com/user_guide/evaluation.html#detections) using FiftyOne’s evaluation API\n",
    "- Viewing the best and worst performing samples in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631da955",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5bfb2",
   "metadata": {},
   "source": [
    "If you haven't already, install FiftyOne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e97ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204060ff",
   "metadata": {},
   "source": [
    "In this tutorial, we’ll use an [Ultralytics](https://www.ultralytics.com/) detection model using the FiftyOne + Ultralytics [integration](https://docs.voxel51.com/integrations/ultralytics.html). To use it, you’ll need to install `ultralytics`, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a46864",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"ultralytics>=8.1.0\" \"torch>=1.8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5c440",
   "metadata": {},
   "source": [
    "## Loading In Our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc122e3",
   "metadata": {},
   "source": [
    "For the walkthrough, we will be using the [MSCOCO 2017](https://cocodataset.org/#home) validation split from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#coco-2017). We can load it in with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    dataset_name=\"evaluate-detections-tutorial\",\n",
    ")\n",
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169388e1",
   "metadata": {},
   "source": [
    "We can see the fields on our dataset by printing it out. Here we can see that MSCOCO 2017 comes with the `ground_truth` detections field prepopulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e654917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        evaluate-detections-tutorial\n",
      "Media type:  image\n",
      "Num samples: 5000\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f6e96",
   "metadata": {},
   "source": [
    "We can also inspect a detection to get an idea of the format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf12a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '663ba4b4cff68a59420a974f',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'potted plant',\n",
      "    'bounding_box': [\n",
      "        0.37028125,\n",
      "        0.3345305164319249,\n",
      "        0.038593749999999996,\n",
      "        0.16314553990610328,\n",
      "    ],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "    'supercategory': 'furniture',\n",
      "    'iscrowd': 0,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "# Print a ground truth detection\n",
    "sample = dataset.first()\n",
    "print(sample.ground_truth.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea3dc6",
   "metadata": {},
   "source": [
    "Before we go further, let’s launch the FiftyOne App and use the GUI to explore the dataset visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2759630",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73fb62",
   "metadata": {},
   "source": [
    "![coco](../assets/coco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfc939",
   "metadata": {},
   "source": [
    "## Add Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c1c46",
   "metadata": {},
   "source": [
    "Now let’s generate some predictions to analyze.\n",
    "\n",
    "We can load the model from the FiftyOne Model Zoo or from Ultralytics and then can apply it directly to our dataset (or any subset thereof) for inference using the sample collection’s `apply_model()` method. Here we load from the [Model Zoo](https://docs.voxel51.com/user_guide/model_zoo/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92617f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"yolov8s-coco-torch\")\n",
    "\n",
    "dataset.apply_model(model, label_field=\"predictions\")\n",
    "\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cee5c2",
   "metadata": {},
   "source": [
    "Now we can check out our predictions on our dataset below! Trying exploring the newly added predictions by playing with the sidebar. Try adding or removing classes or moving the confidence threshold!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21154aba",
   "metadata": {},
   "source": [
    "![Yolo-COCO](../assets/coco-yolo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357171ac",
   "metadata": {},
   "source": [
    "## Analyzing Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4cb9d",
   "metadata": {},
   "source": [
    "Let’s analyze the raw predictions we’ve added to our dataset in more detail. FiftyOne provides the ability to write [expressions](https://docs.voxel51.com/user_guide/using_views.html#filtering) that match, filter, and sort detections based on their attributes. See using [DatasetViews](https://docs.voxel51.com/user_guide/using_views.html) for full details.\n",
    "\n",
    "We can start by creating a view that filters our labels so to only have detections that have a `confidence` higher than 0.75.\n",
    "\n",
    "Note the `only_matches=False` argument. When filtering labels, any samples that no longer contain labels would normally be removed from the view. However, this is not desired when performing evaluations since it can skew your results between views. We set `only_matches=False` so that all samples will be retained, even if some no longer contain labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042b607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(\"predictions\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6188dda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     evaluate-detections-tutorial\n",
      "Media type:  image\n",
      "Num samples: 5000\n",
      "Sample fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    predictions:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "View stages:\n",
      "    1. FilterLabels(field='predictions', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the view\n",
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31134bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '664289ef3962bfad6410992d',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'tv',\n",
      "    'bounding_box': [\n",
      "        0.007986664772033691,\n",
      "        0.3902428150177002,\n",
      "        0.23381657898426056,\n",
      "        0.22575199604034424,\n",
      "    ],\n",
      "    'mask': None,\n",
      "    'confidence': 0.9355676174163818,\n",
      "    'index': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.predictions.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a426d62",
   "metadata": {},
   "source": [
    "There are multiple situations where it can be useful to visualize each object separately. For example, if a sample contains dozens of objects overlapping one another or if you want to look specifically for instances of a class of objects.\n",
    "\n",
    "You can view our dataset as a set of Object Patches as well using the [patches view button](https://docs.voxel51.com/user_guide/app.html#viewing-object-patches)! The button allows you to take any Detections field in your dataset and visualize each object as an individual patch in the image grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecead88",
   "metadata": {},
   "source": [
    "![object-patches](../assets/object-patches.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff6b21",
   "metadata": {},
   "source": [
    "## Evaluate detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed1711",
   "metadata": {},
   "source": [
    "Now that we have samples with ground truth and predicted objects, let’s use FiftyOne to evaluate the quality of the detections.\n",
    "\n",
    "FiftyOne provides a powerful [evaluation API](https://docs.voxel51.com/user_guide/evaluation.html) that contains a collection of methods for performing evaluation of model predictions. Since we’re working with object detections here, we’ll use [detection evaluation](https://docs.voxel51.com/user_guide/evaluation.html#detections)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eac345",
   "metadata": {},
   "source": [
    "### Running Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881535c",
   "metadata": {},
   "source": [
    "We can run evaluation on our samples via [evaluate_detections()](https://docs.voxel51.com/api/fiftyone.core.collections.html#fiftyone.core.collections.SampleCollection.evaluate_detections). Note that this method is available on both the `Dataset` and `DatasetView` classes, which means that we can run evaluation on our high_conf_view to assess the quality of only the high confidence predictions in our dataset.\n",
    "\n",
    "By default, this method will use the [COCO evaluation protocol](https://cocodataset.org/#detection-eval), plus some extra goodies that we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ed4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `predictions` field of our dataset\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a14f04",
   "metadata": {},
   "source": [
    "### Aggregate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f12309",
   "metadata": {},
   "source": [
    "The `results` object returned by the evaluation routine provides a number of convenient methods for analyzing our predictions.\n",
    "\n",
    "For example, let’s print a classification report for the top-10 most common classes in the dataset, as well as the mAP score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdc9226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       person       0.85      0.75      0.79     11723\n",
      "         kite       0.74      0.65      0.69       365\n",
      "          car       0.73      0.63      0.67      1979\n",
      "         bird       0.80      0.52      0.63       487\n",
      "       carrot       0.55      0.46      0.50       411\n",
      "         boat       0.62      0.45      0.52       436\n",
      "    surfboard       0.70      0.57      0.63       269\n",
      "     airplane       0.79      0.87      0.83       143\n",
      "traffic light       0.68      0.47      0.56       637\n",
      "        bench       0.55      0.37      0.45       413\n",
      "\n",
      "    micro avg       0.80      0.69      0.74     16863\n",
      "    macro avg       0.70      0.57      0.63     16863\n",
      " weighted avg       0.80      0.69      0.74     16863\n",
      "\n",
      "Yolov8s mAP score: 0.39593808224616606\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)\n",
    "\n",
    "# Print out the mAP score\n",
    "print(f\"Yolov8s mAP score: {results.mAP()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3aef2",
   "metadata": {},
   "source": [
    "We can also evaluate our detections on specific view. For instance, we can evaluate our detections on our `high_conf_view` from before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9d5b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 5000/5000 [31.9s elapsed, 0s remaining, 158.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 5000/5000 [23.1s elapsed, 0s remaining, 226.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions in the `predictions` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval_high_conf\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ef08d",
   "metadata": {},
   "source": [
    "We can also create widgets in our jupyter notebook to display interactive graphs like PR curves. Let's try below, making sure that we have the correct version of `ipywidgets` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701945e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'ipywidgets>=8,<9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f49dfe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f23f350a66d49b496778c84939470fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([    0.96414,     0.94467,     0.93928,     0.93412,     0.93048,\n",
       "                                       0.92616,      0.9225,       0.919,     0.91503,     0.91094,\n",
       "                                       0.90676,     0.90267,     0.89791,     0.89257,     0.88409,\n",
       "                                       0.80297,     0.79909,     0.79541,     0.79203,     0.78861,\n",
       "                                       0.78479,     0.78045,     0.77582,     0.77094,     0.76531,\n",
       "                                       0.75879,     0.75229,     0.74514,     0.66498,     0.65954,\n",
       "                                        0.6533,     0.64692,     0.64031,     0.63343,     0.55195,\n",
       "                                       0.54611,     0.46507,     0.45966,     0.37968,     0.22583,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0]),\n",
       "              'hovertemplate': ('<b>class: %{text}</b><br>recal' ... 'customdata:.3f}<extra></extra>'),\n",
       "              'line': {'color': '#3366CC'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'person (AP = 0.328)',\n",
       "              'text': array(['person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person', 'person', 'person', 'person', 'person',\n",
       "                             'person', 'person', 'person'], dtype='<U6'),\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c484e3b7-f8ed-401d-b061-ff8756643f76',\n",
       "              'x': array([          0,        0.01,        0.02,        0.03,        0.04,\n",
       "                                 0.05,        0.06,        0.07,        0.08,        0.09,\n",
       "                                  0.1,        0.11,        0.12,        0.13,        0.14,\n",
       "                                 0.15,        0.16,        0.17,        0.18,        0.19,\n",
       "                                  0.2,        0.21,        0.22,        0.23,        0.24,\n",
       "                                 0.25,        0.26,        0.27,        0.28,        0.29,\n",
       "                                  0.3,        0.31,        0.32,        0.33,        0.34,\n",
       "                                 0.35,        0.36,        0.37,        0.38,        0.39,\n",
       "                                  0.4,        0.41,        0.42,        0.43,        0.44,\n",
       "                                 0.45,        0.46,        0.47,        0.48,        0.49,\n",
       "                                  0.5,        0.51,        0.52,        0.53,        0.54,\n",
       "                                 0.55,        0.56,        0.57,        0.58,        0.59,\n",
       "                                  0.6,        0.61,        0.62,        0.63,        0.64,\n",
       "                                 0.65,        0.66,        0.67,        0.68,        0.69,\n",
       "                                  0.7,        0.71,        0.72,        0.73,        0.74,\n",
       "                                 0.75,        0.76,        0.77,        0.78,        0.79,\n",
       "                                  0.8,        0.81,        0.82,        0.83,        0.84,\n",
       "                                 0.85,        0.86,        0.87,        0.88,        0.89,\n",
       "                                  0.9,        0.91,        0.92,        0.93,        0.94,\n",
       "                                 0.95,        0.96,        0.97,        0.98,        0.99,\n",
       "                                    1]),\n",
       "              'y': array([     0.9875,     0.97968,     0.96698,      0.9644,     0.95972,\n",
       "                              0.95473,     0.94894,     0.94534,     0.94104,     0.93504,\n",
       "                              0.92955,     0.92505,     0.92169,     0.91713,     0.90901,\n",
       "                              0.86836,      0.8663,     0.86467,     0.86348,     0.86052,\n",
       "                              0.85879,      0.8562,     0.85362,     0.85149,     0.84916,\n",
       "                              0.84592,     0.84148,     0.83781,     0.76779,     0.76578,\n",
       "                              0.76378,     0.76105,     0.75918,     0.75716,       0.672,\n",
       "                              0.67033,     0.57928,     0.57852,     0.48493,     0.29311,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0])},\n",
       "             {'customdata': array([    0.96012,     0.93258,     0.92213,     0.91302,     0.90499,\n",
       "                                       0.89587,     0.88296,     0.80138,     0.79426,     0.78737,\n",
       "                                       0.78029,     0.77429,     0.76886,     0.76141,     0.75578,\n",
       "                                        0.7479,     0.73759,     0.72928,     0.64653,     0.63753,\n",
       "                                       0.62988,     0.62099,     0.53931,     0.45776,     0.37709,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0,           0,           0,           0,           0,\n",
       "                                             0]),\n",
       "              'hovertemplate': ('<b>class: %{text}</b><br>recal' ... 'customdata:.3f}<extra></extra>'),\n",
       "              'line': {'color': '#DC3912'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'car (AP = 0.204)',\n",
       "              'text': array(['car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car',\n",
       "                             'car'], dtype='<U3'),\n",
       "              'type': 'scatter',\n",
       "              'uid': '5a81a84e-3f5d-494c-9bc3-4e759d01c93d',\n",
       "              'x': array([          0,        0.01,        0.02,        0.03,        0.04,\n",
       "                                 0.05,        0.06,        0.07,        0.08,        0.09,\n",
       "                                  0.1,        0.11,        0.12,        0.13,        0.14,\n",
       "                                 0.15,        0.16,        0.17,        0.18,        0.19,\n",
       "                                  0.2,        0.21,        0.22,        0.23,        0.24,\n",
       "                                 0.25,        0.26,        0.27,        0.28,        0.29,\n",
       "                                  0.3,        0.31,        0.32,        0.33,        0.34,\n",
       "                                 0.35,        0.36,        0.37,        0.38,        0.39,\n",
       "                                  0.4,        0.41,        0.42,        0.43,        0.44,\n",
       "                                 0.45,        0.46,        0.47,        0.48,        0.49,\n",
       "                                  0.5,        0.51,        0.52,        0.53,        0.54,\n",
       "                                 0.55,        0.56,        0.57,        0.58,        0.59,\n",
       "                                  0.6,        0.61,        0.62,        0.63,        0.64,\n",
       "                                 0.65,        0.66,        0.67,        0.68,        0.69,\n",
       "                                  0.7,        0.71,        0.72,        0.73,        0.74,\n",
       "                                 0.75,        0.76,        0.77,        0.78,        0.79,\n",
       "                                  0.8,        0.81,        0.82,        0.83,        0.84,\n",
       "                                 0.85,        0.86,        0.87,        0.88,        0.89,\n",
       "                                  0.9,        0.91,        0.92,        0.93,        0.94,\n",
       "                                 0.95,        0.96,        0.97,        0.98,        0.99,\n",
       "                                    1]),\n",
       "              'y': array([          1,     0.93079,     0.92772,     0.92423,     0.91686,\n",
       "                              0.90586,     0.89879,     0.87307,     0.87288,     0.87263,\n",
       "                              0.87052,     0.86608,     0.86367,     0.85381,     0.84776,\n",
       "                              0.84298,     0.83447,     0.83111,     0.76054,     0.75603,\n",
       "                              0.75001,     0.74533,     0.66054,     0.57041,     0.47641,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0,           0,           0,           0,           0,\n",
       "                                    0])}],\n",
       "    'layout': {'margin': {'b': 0, 'l': 0, 'r': 0, 't': 30},\n",
       "               'shapes': [{'line': {'dash': 'dash'}, 'type': 'line', 'x0': 0, 'x1': 1, 'y0': 1, 'y1': 0}],\n",
       "               'template': '...',\n",
       "               'xaxis': {'constrain': 'domain', 'range': [0, 1], 'title': {'text': 'Recall'}},\n",
       "               'yaxis': {'constrain': 'domain',\n",
       "                         'range': [0, 1],\n",
       "                         'scaleanchor': 'x',\n",
       "                         'scaleratio': 1,\n",
       "                         'title': {'text': 'Precision'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = results.plot_pr_curves(classes=[\"person\", \"car\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe9323",
   "metadata": {},
   "source": [
    "### Evaluation Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5aa79",
   "metadata": {},
   "source": [
    "So, now that we have a sense for the aggregate performance of our model, let’s dive into sample-level analysis by creating an [evaluation view](https://docs.voxel51.com/user_guide/app.html#viewing-evaluation-patches).\n",
    "\n",
    "Any evaluation that you stored on your dataset can be used to generate an [evaluation view](https://docs.voxel51.com/user_guide/app.html#viewing-evaluation-patches) that is a patches view creating a sample for every true positive, false positive, and false negative in your dataset. Through this view, you can quickly filter and sort evaluated detections by their type (TP/FP/FN), evaluated IoU, and if they are matched to a crowd object.\n",
    "\n",
    "These evaluation views can be created through Python or directly in the App as shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b4a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     evaluate-detections-tutorial\n",
      "Media type:  image\n",
      "Num patches: 45509\n",
      "Patch fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    sample_id:    fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    predictions:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    crowd:        fiftyone.core.fields.BooleanField\n",
      "    type:         fiftyone.core.fields.StringField\n",
      "    iou:          fiftyone.core.fields.FloatField\n",
      "View stages:\n",
      "    1. ToEvaluationPatches(eval_key='eval', config=None)\n"
     ]
    }
   ],
   "source": [
    "eval_patches = dataset.to_evaluation_patches(\"eval\")\n",
    "print(eval_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = eval_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856ae4f",
   "metadata": {},
   "source": [
    "![eval_patches](../assets/eval_patches.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216974c",
   "metadata": {},
   "source": [
    "## View the best-performing samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61e486",
   "metadata": {},
   "source": [
    "To dig in further, let’s create a view that sorts by eval_tp so we can see the best-performing cases of our model (i.e., the samples with the most correct predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show samples with most true positives\n",
    "session.view = high_conf_view.sort_by(\"eval_tp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0dfaa",
   "metadata": {},
   "source": [
    "Similarly, we can sort by the eval_fp field to see the worst-performing cases of our model (i.e., the samples with the most false positive predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b575d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show samples with most false positives\n",
    "session.view = high_conf_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5687a0",
   "metadata": {},
   "source": [
    "## Filtering by Bounding Box Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f54c0",
   "metadata": {},
   "source": [
    "Dataset views are extremely powerful. For example, let’s look at how our model performed on small objects by creating a view that contains only predictions whose bounding box area is less than `32^2` pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5aabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metadata so we can reference image height/width in our view\n",
    "dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create an expression that will match objects whose bounding boxes have\n",
    "# area less than 32^2 pixels\n",
    "#\n",
    "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
    "# with relative coordinates in [0, 1], so we multiply by image\n",
    "# dimensions to get pixel area\n",
    "#\n",
    "bbox_area = (\n",
    "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
    "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
    ")\n",
    "small_boxes = bbox_area < 32 ** 2\n",
    "\n",
    "# Create a view that contains only small (and high confidence) predictions\n",
    "small_boxes_view = high_conf_view.filter_labels(\"predictions\", small_boxes)\n",
    "\n",
    "session.view = small_boxes_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c1bc5",
   "metadata": {},
   "source": [
    "![eval_boxes](../assets/eval_boxes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a196c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view that contains only small GT and predicted boxes\n",
    "small_boxes_eval_view = (\n",
    "    high_conf_view\n",
    "    .filter_labels(\"ground_truth\", small_boxes, only_matches=False)\n",
    "    .filter_labels(\"predictions\", small_boxes, only_matches=False)\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194ff99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       person       0.89      0.02      0.05      3217\n",
      "          car       0.91      0.05      0.09      1005\n",
      "         book       0.00      0.00      0.00       677\n",
      "       bottle       0.88      0.03      0.06       521\n",
      "traffic light       1.00      0.02      0.05       490\n",
      "        chair       0.67      0.00      0.01       461\n",
      "          cup       0.82      0.05      0.09       379\n",
      "      handbag       0.00      0.00      0.00       235\n",
      "         bird       0.71      0.02      0.04       234\n",
      "  sports ball       0.93      0.32      0.47       218\n",
      "\n",
      "    micro avg       0.89      0.03      0.06      7437\n",
      "    macro avg       0.68      0.05      0.09      7437\n",
      " weighted avg       0.77      0.03      0.06      7437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common small object classes\n",
    "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
    "classes_top10_small = sorted(small_counts, key=small_counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 small object classes\n",
    "small_boxes_results.print_report(classes=classes_top10_small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
